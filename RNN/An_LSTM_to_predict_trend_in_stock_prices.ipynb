{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Avrrtctrnjnh"
   },
   "source": [
    "A Long Short-term Memory (LSTM) which predicts upwards or downwards trend for GOOG stock price for next 18 days. LSTM is a type of Recurring Neural Network (RNN), where we set the value of Recurring weights (W rec) as 1. \n",
    "\n",
    "LSTM is expected to perform better than ARIMA model. Dropout regularisation will avoid overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lazQ9Whtr9Ig"
   },
   "source": [
    "# Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_PhdSvbysC85"
   },
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "tYM5WJcvnFaq"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6obolcUsOCH"
   },
   "source": [
    "## Importing the Training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rIH6HBDPscIR"
   },
   "source": [
    "Keeping separate the training and test set so that RNN is not acquainted with test set. \n",
    "\n",
    "Creating a numpy array from the open price column using iloc because that is what we are interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "2ah5cfe9s279"
   },
   "outputs": [],
   "source": [
    "dataset_train = pd.read_csv('Google_Stock_Price_Train.csv')\n",
    "training_set = dataset_train.iloc[:, 1:2].values\n",
    "# : selects all the rows. we use  1:2 for selecting column 2 because that lower bound is selected and upper bound is ingnored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1IUqaF-3uUF0"
   },
   "source": [
    "## Feature Scaling\n",
    "Two common ways of applying Feature Scaling are:\n",
    "\n",
    "* **Standardisation** X(stand) = [X - mean(X)] / stdev(X)\n",
    "\n",
    "* **Normalisation** X(norm) = [X - min(X)] / [max(X) - min(X)]\n",
    "\n",
    "If there is a sigmoid activation function involved in the construction of an RNN, it is recommended to apply Normalisation. MinMaxScalar class from scikit learn library is used to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "jBzKZSrOt-Fp"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# creating an object sc in minmaxscalar class. Normalising(Scaling) stock prices between 0 and 1\n",
    "sc = MinMaxScaler(feature_range = (0,1))\n",
    "# using fit_transform method for scaling training_set\n",
    "training_set_scaled = sc.fit_transform(training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LF57ybivyBBN"
   },
   "source": [
    "## Number of timesteps and output\n",
    "This datastructure specifies what our RNN needs to remember when predicting next stock price. \n",
    "\n",
    "It is important to have an optimal number of timesteps or else it might lead to overfitting or non-sense predictions\n",
    "\n",
    "Here we choose 60 timesteps (approx. 3 months since we have daily data) and 1 output. This means that our RNN will try to learn from 60 past prices to understand some trend and on the basis of that, it will predict the next price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "8hiYc7npxyX0"
   },
   "outputs": [],
   "source": [
    "# Creating empty lists for inputs to Neural Network (x_train) and output (y_train)\n",
    "# for each day x_train will contain 60 previous day prices, and y_train will contan next day's predicted price\n",
    "x_train = []\n",
    "y_train = []\n",
    "# populating these empty lists with a for loop. we need to start with the 61st observation to get 60 previous prices\n",
    "# Total observations in training set are 1257\n",
    "for i in range(60, 1258):\n",
    "  x_train.append(training_set_scaled[i-60 : i, 0]) # choosing previous 60 observations in column 1 (We only have one column)\n",
    "  y_train.append(training_set_scaled[i , 0])\n",
    "# creating a numpy array with these lists\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HtHcLaRY29AF"
   },
   "source": [
    "## Reshaping\n",
    "Adds the number of predictors to predict stock prices. This could be other stock's prices or another time-series data. It is done using input_dim\n",
    "Keras expects inputs for RNN as N-D tensor with shape [batch_size, timesteps, ...] or [timesteps, batch_size, ...] when time_major is True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "AqHfLuS_2TeF"
   },
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "# selecting number of rows uisng [0] and number of columns using [1]. The 1 at the end is the number of predictors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mf571GxkZYT9"
   },
   "source": [
    "# Part 2: Building an RNN\n",
    "a stacked LSTM with dropout  regularisation to avoid overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9sKz_U5WZvVv"
   },
   "source": [
    "## Importing Keras libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "_LhnS76S7rsx"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LNnb6z9dhrXD"
   },
   "source": [
    "## Initialising the RNN\n",
    "Initialise the Reccuring Neural Network as a sequence of layers.\n",
    "\n",
    "We are predicting continuous outcomes (prices), hence we need to perform regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "L2mp8ePyaEMA"
   },
   "outputs": [],
   "source": [
    "regressor = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVHkQosxitVP"
   },
   "source": [
    "## Adding first LSTM layer and dropout regularisation\n",
    "\n",
    "it is better to choose a large number of units(neurons) for higher dimensionality. Return sequences is set to True because we have multiple layers. Using dropout we can specify the number of neurons to ignore during regularisation. Here we use 20% dropout. So during forward and backpropagation 20% of neurons (10) will be ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "EN3NwlEoizAb"
   },
   "outputs": [],
   "source": [
    "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (x_train.shape[1], 1)))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nIuPWxDlhin"
   },
   "source": [
    "## Adding second LSTM layer and dropout regularisation\n",
    "we do not need to specify the input shape again when adding next LSTM layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "I4OEC2kVk09N"
   },
   "outputs": [],
   "source": [
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YmUHmYbamP4K"
   },
   "source": [
    "## Adding third LSTM layer and dropout regularisation\n",
    "same as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "ndTtZkJFmHC7"
   },
   "outputs": [],
   "source": [
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "If1ws5MfmaHO"
   },
   "source": [
    "## Adding fourth LSTM layer and dropout regularisation\n",
    "Since, this is the final layer of our RNN, we set return_sequences to False or remove it, because we are not returning any sequences here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "AsJOVCHGmYVZ"
   },
   "outputs": [],
   "source": [
    "regressor.add(LSTM(units = 50, return_sequences = False))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O8m5t6gWpqhi"
   },
   "source": [
    "## Adding the output layer\n",
    "Since we only have one predicted output (price) we have one unit.\n",
    "Dense class is fully connected to other layers, so we use it for output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "yaakaFc1pohw"
   },
   "outputs": [],
   "source": [
    "regressor.add(Dense(units = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8Od5Pd6wCqi"
   },
   "source": [
    "## Compiling the RNN\n",
    "A lot of optimisers can be used. Keras suggests to use RMSprop for RNN networks https://keras.io/api/optimizers/. We can also try Adam optimiser to see the difference later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "0And1G81to2r"
   },
   "outputs": [],
   "source": [
    "regressor.compile(optimizer = 'rmsprop', loss = 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KM2lF_NPHNPb"
   },
   "source": [
    "## Fitting the RNN to the Training Set\n",
    "If we try to minimise the loss to an extreme extent, it would indicate overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "48sk-qGqHEyV",
    "outputId": "e7ecf2df-6e00-496d-a601-4762242ec56b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "38/38 [==============================] - 12s 126ms/step - loss: 0.0322\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 5s 123ms/step - loss: 0.0148\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 5s 125ms/step - loss: 0.0121\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 5s 126ms/step - loss: 0.0099\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 5s 126ms/step - loss: 0.0098\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 5s 124ms/step - loss: 0.0093\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 5s 126ms/step - loss: 0.0080\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 5s 124ms/step - loss: 0.0069\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 5s 125ms/step - loss: 0.0072\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 5s 125ms/step - loss: 0.0072\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 5s 124ms/step - loss: 0.0058\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 5s 126ms/step - loss: 0.0062\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 5s 125ms/step - loss: 0.0061\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 5s 128ms/step - loss: 0.0053\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 5s 125ms/step - loss: 0.0056\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 5s 126ms/step - loss: 0.0052\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 5s 125ms/step - loss: 0.0044\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 5s 126ms/step - loss: 0.0048\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 5s 125ms/step - loss: 0.0045\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 5s 127ms/step - loss: 0.0044\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 5s 125ms/step - loss: 0.0036\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 5s 127ms/step - loss: 0.0045\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 5s 126ms/step - loss: 0.0044\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 0.0038\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 5s 127ms/step - loss: 0.0038\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 5s 127ms/step - loss: 0.0036\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 5s 128ms/step - loss: 0.0037\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 5s 127ms/step - loss: 0.0033\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 5s 128ms/step - loss: 0.0034\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 5s 128ms/step - loss: 0.0029\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 5s 127ms/step - loss: 0.0034\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 5s 132ms/step - loss: 0.0029\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 5s 133ms/step - loss: 0.0031\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 5s 134ms/step - loss: 0.0030\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 5s 134ms/step - loss: 0.0031\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 5s 133ms/step - loss: 0.0028\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 0.0027\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 5s 132ms/step - loss: 0.0028\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 5s 128ms/step - loss: 0.0030\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 0.0029\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 5s 136ms/step - loss: 0.0026\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 0.0026\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 0.0027\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 5s 131ms/step - loss: 0.0026\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 0.0027\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 0.0024\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 5s 125ms/step - loss: 0.0024\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 5s 122ms/step - loss: 0.0023\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 5s 124ms/step - loss: 0.0024\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 5s 122ms/step - loss: 0.0024\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 5s 122ms/step - loss: 0.0024\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 5s 124ms/step - loss: 0.0023\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 5s 125ms/step - loss: 0.0022\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 5s 123ms/step - loss: 0.0022\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 5s 124ms/step - loss: 0.0024\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 5s 124ms/step - loss: 0.0021\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 5s 123ms/step - loss: 0.0023\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 5s 123ms/step - loss: 0.0022\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 5s 121ms/step - loss: 0.0023\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 5s 121ms/step - loss: 0.0021\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 5s 122ms/step - loss: 0.0021\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 5s 125ms/step - loss: 0.0023\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 5s 123ms/step - loss: 0.0022\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 5s 123ms/step - loss: 0.0021\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 5s 123ms/step - loss: 0.0019\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 5s 123ms/step - loss: 0.0018\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 5s 124ms/step - loss: 0.0019\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 5s 124ms/step - loss: 0.0019\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 5s 124ms/step - loss: 0.0019\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 5s 123ms/step - loss: 0.0017\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 5s 124ms/step - loss: 0.0021\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 5s 123ms/step - loss: 0.0019\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 5s 125ms/step - loss: 0.0018\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 5s 123ms/step - loss: 0.0018\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 5s 125ms/step - loss: 0.0019\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 5s 125ms/step - loss: 0.0019\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 5s 123ms/step - loss: 0.0018\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 5s 123ms/step - loss: 0.0019\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 5s 123ms/step - loss: 0.0020\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 5s 123ms/step - loss: 0.0016\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 5s 122ms/step - loss: 0.0019\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 5s 122ms/step - loss: 0.0018\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 5s 123ms/step - loss: 0.0015\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 5s 123ms/step - loss: 0.0017\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 5s 122ms/step - loss: 0.0016\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 5s 122ms/step - loss: 0.0018\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 5s 122ms/step - loss: 0.0015\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 5s 122ms/step - loss: 0.0016\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 5s 122ms/step - loss: 0.0017\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 5s 122ms/step - loss: 0.0017\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 5s 120ms/step - loss: 0.0015\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 5s 123ms/step - loss: 0.0016\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 5s 122ms/step - loss: 0.0015\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 5s 123ms/step - loss: 0.0015\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 5s 122ms/step - loss: 0.0016\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 5s 123ms/step - loss: 0.0015\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 5s 124ms/step - loss: 0.0017\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 5s 127ms/step - loss: 0.0015\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 5s 125ms/step - loss: 0.0017\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 5s 124ms/step - loss: 0.0016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f121e155250>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(x = x_train, y = y_train, batch_size = 32, epochs = 100 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ld25wIOTKPY4"
   },
   "source": [
    "# Part 3: Making Predictions and Visualising Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dndrGbP9K4Cz"
   },
   "source": [
    "## Getting the real GOOG price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "dw59VIFhICnq"
   },
   "outputs": [],
   "source": [
    "dataset_test = pd.read_csv('Google_Stock_Price_Test.csv')\n",
    "real_stock_price = dataset_test.iloc[:, 1:2].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JChPwpDLLzb8"
   },
   "source": [
    "# Predicting price for GOOG\n",
    "\n",
    "We would need to concatenate prices from the training set to test set so that for each day in test set we have access to previous 60 day open prices\n",
    "\n",
    "But concatenation need to be performed on original dataset_train and dataset_test. From this concatenation we would get input from each prediction (i.e. the 60 previous prices at each time t), which will then be scaled. We are only scaling the inputs and not changing actual test values.\n",
    "\n",
    "We need to scale inputs here because our RNN was trained on scaled inputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "9TdVnL5PLan2"
   },
   "outputs": [],
   "source": [
    "dataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']), axis = 0) # for vertical concatenation, axis = 0\n",
    "inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60 : ].values\n",
    "# we are choosing 60 previous values from dataset_train for our prediction number 1\n",
    "inputs = inputs.reshape(-1, 1) # this gets input for stock prices in 1 column\n",
    "inputs = sc.transform(inputs) \n",
    "# scaling the inputs. do not need to use fit_transform because sc object was already fitted to training set\n",
    "# scaling must be the same on which our regressor was trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "OPF3WRAGLbwT"
   },
   "outputs": [],
   "source": [
    "# we do not need y_test because we making predictions\n",
    "# the test set contains only 20 financial days so the upper bound in for loop would be 60+20 = 80\n",
    "x_test = []\n",
    "for i in range (60, 80):\n",
    "  x_test.append(inputs[i-60 : i, 0])\n",
    "x_test = np.array(x_test)\n",
    "# creating a 3-d structure for keras\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "c0KrTBgUb1J-"
   },
   "outputs": [],
   "source": [
    "# saving predictions in predicted_stock_price\n",
    "predicted_stock_price = regressor.predict(x_test)\n",
    "# applying the inverse transform scaling method to get unscaled values\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "372jz_Kicwu1"
   },
   "source": [
    "## Visualising the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "PdP0dcmZciXl",
    "outputId": "75805bf2-64d3-4c9e-c278-3db26c1bcbed"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting the real GOOG stock price\n",
    "plt.plot(real_stock_price, color = 'red', label = 'Real GOOG price')\n",
    "plt.plot(predicted_stock_price, color = 'blue', label = 'Predicted GOOG price')\n",
    "plt.title('GOOG Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('GOOG Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z5fSq_Yydvow"
   },
   "source": [
    "In most parts of our predictions we see predicted results lagging the actual price. Our model can not react fast enough to sudden chances, But model reacts very well to smooth changes and manages to follow the trend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RpBnSSv_e9SY"
   },
   "source": [
    "# Part 4: Closing Comments\n",
    "\n",
    "**Some ways to further improve the RNN model:**\n",
    "\n",
    "  Getting more training data\n",
    "\n",
    "  Increasing the number of timesteps\n",
    "\n",
    "  Adding some other indicators (other stocks which might be correlated to our chosen stock\n",
    "\n",
    "  Adding more LSTM layers: this RNN had four LSTM layers but it could be experimented with\n",
    "\n",
    "  Adding more neurons in the LSTM layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "393RjdyXfilT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Building an LSTM to predict trend in stock prices.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
