{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Building an ANN (for classification).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmSt2FhQuiDs"
      },
      "source": [
        "# Artificial Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbXZuvtZueqh"
      },
      "source": [
        "* We have a dataset of a bank which contains information about customer (credit score, geography, gender, age, balance, tenure, number of products used, activity, estimated salary... AND whether the customer remains the client of the bank 6 months hence)\n",
        "* The following is an ANN algorithm to determine whether a new/ existing client, given above information, would stay a bank's client or not\n",
        "* This is called Churn Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jPdiQ4xvPiB"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ubk52-pFvYfx"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "IUKWNj8twCRe",
        "outputId": "b1fd56e4-8a1d-405e-e2af-8f788e746620"
      },
      "source": [
        "tf.__version__   # prints the version of tensorflow being used"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.6.0'"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVJmz_xev15T"
      },
      "source": [
        "## Part 1: Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUdetEU5wkob"
      },
      "source": [
        "### Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4saBrQ5Yvlxq"
      },
      "source": [
        "dataset = pd.read_csv('Churn_Modelling.csv')\n",
        "# The first 3 columns in dataset have absolutely no impact on the outcome\n",
        "# so we ignore them. Although the NN would sense that instinctively anyway\n",
        "x = dataset.iloc[:, 3 : -1].values # taking columns from 4th till second last\n",
        "y = dataset.iloc[:, -1].values # taking only last column"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQUWczAey6A9",
        "outputId": "d3d2db6a-65d4-4ba6-9f2a-07da51ddb32f"
      },
      "source": [
        "# the independent variables\n",
        "print (x)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[619 'France' 'Female' ... 1 1 101348.88]\n",
            " [608 'Spain' 'Female' ... 0 1 112542.58]\n",
            " [502 'France' 'Female' ... 1 0 113931.57]\n",
            " ...\n",
            " [709 'France' 'Female' ... 0 1 42085.58]\n",
            " [772 'Germany' 'Male' ... 1 0 92888.52]\n",
            " [792 'France' 'Female' ... 1 0 38190.78]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xysubihy_6Z",
        "outputId": "b75c152b-2d0f-409f-f332-b3ef57c2f5ff"
      },
      "source": [
        "# the dependent variable\n",
        "print (y)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 1 ... 1 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1434Pae3zVeT"
      },
      "source": [
        "### Encoding categorical data\n",
        "There are two categorical variables: Customer's country, and customer's gender. They need to be encoded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XXJqP_0z5dz"
      },
      "source": [
        "Label encoding the 'Gender' column, with index 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1ivA9fuzC_G"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "x[:, 2] = le.fit_transform(x[:, 2]) "
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9YJwjnp1JE3",
        "outputId": "0c2e6fbe-146d-445b-96af-0c58e1a534c4"
      },
      "source": [
        "# We observe that 'Female' was encoded as 0 and 'Male' as 1\n",
        "print (x)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[619 'France' 0 ... 1 1 101348.88]\n",
            " [608 'Spain' 0 ... 0 1 112542.58]\n",
            " [502 'France' 0 ... 1 0 113931.57]\n",
            " ...\n",
            " [709 'France' 0 ... 0 1 42085.58]\n",
            " [772 'Germany' 1 ... 1 0 92888.52]\n",
            " [792 'France' 0 ... 1 0 38190.78]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e1kIb821h32"
      },
      "source": [
        "One Hot Encoding the 'Geography' column. This needs to be done because there is no binary relationship among geographies as with 'Gender' in our dataset. Index for geography column is 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4S5wpTNx1LDJ"
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct = ColumnTransformer(transformers = [('encoder', OneHotEncoder(), [1])], remainder = 'passthrough')\n",
        "x = np.array(ct.fit_transform(x))"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lNGxPEQ3cLe",
        "outputId": "c2a0aa1d-3e7e-4f76-fac5-aa79a7e4be6c"
      },
      "source": [
        "# We observe that France was encoded as 1, 0, 0 Spain as 0, 0, 1 and Germany as 0, 1, 0\n",
        "print(x)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.0 0.0 0.0 ... 1 1 101348.88]\n",
            " [0.0 0.0 1.0 ... 0 1 112542.58]\n",
            " [1.0 0.0 0.0 ... 1 0 113931.57]\n",
            " ...\n",
            " [1.0 0.0 0.0 ... 0 1 42085.58]\n",
            " [0.0 1.0 0.0 ... 1 0 92888.52]\n",
            " [1.0 0.0 0.0 ... 1 0 38190.78]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXzOwC_k4KMs"
      },
      "source": [
        "### Splitting dataset into Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGxDn-1U3dtP"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size = 0.2, random_state = 0)"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpSu5ile4z9t"
      },
      "source": [
        "Feature Scaling: fundamental for Deep Learning, applied to all features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_hciNXL4Hup"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "x_train = sc.fit_transform(x_train) # Scaler object is only fitted to training set to avoid information leakage\n",
        "x_test = sc.transform(x_test)"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2spzceg25_RS"
      },
      "source": [
        "## Part 2: Building the ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FFABvQX6NMw"
      },
      "source": [
        "### Initialising the ANN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KWNZbil5zng"
      },
      "source": [
        "# Creating an ANN variable as an object of a sequential class in layers\n",
        "ann = tf.keras.models.Sequential()"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0EoA01v7J4a"
      },
      "source": [
        "### Adding the input layer and the first hidden layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkhcHF8Z_9lv"
      },
      "source": [
        "using Dense class and specifying number of neurons, and activation function (rectifier is relu)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lI9PEQnA5-aw"
      },
      "source": [
        "ann.add(tf.keras.layers.Dense(units = 6, activation = 'relu'))"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKBmz3Ll80hA"
      },
      "source": [
        "### Adding the second hidden layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SoN_5f_AFWh"
      },
      "source": [
        "by simply copying the code from first layer above. Add method can add any layer this way at any stage of construction of ANN. The number of neurons and activation function can be changed ofcourse"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIbyLRrY8vKu"
      },
      "source": [
        "ann.add(tf.keras.layers.Dense(units = 6, activation = 'relu'))"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFOPONmk9WBO"
      },
      "source": [
        "### Adding the output layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAAI3DRFAMM3"
      },
      "source": [
        "Dense class is used because we want output layer to be fully connected to the hidden layers. The number of units in the output required is 1, because we only need a binary outcome whether the customer left the bank (1) or stayed with the bank (0).\n",
        "\n",
        "However, if we were doing classification with non-binary dependent variable with e.g. 3 classes A,B,C, we would need 3 dimensions (3 output neurons to OneHotEncode that dependent variable A as 1, 0, 0 B as 0, 1, 0 and C as 0, 0, 1\n",
        "\n",
        "We use the sigmoid activation function for outer layer instead of rectifier (relu), because sigmoid function can also give the probablities that the binary outcome is 1 or 0\n",
        "\n",
        "If the output is non-binary we used Softmax activation function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgia4fQP9e7S"
      },
      "source": [
        "ann.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olmtMmds_qyW"
      },
      "source": [
        "## Part 3: Training the ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyUT0KE6ASi-"
      },
      "source": [
        "### Compiling the ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmqcG-3NAZZe"
      },
      "source": [
        "with an Optimiser, a loss function and metrics\n",
        "\n",
        "Adam optimiser can perform stochastic gradient descent \n",
        "\n",
        "for binary output classification (as in our case), loss function used is binary_crossentropy\n",
        "\n",
        "for non-binary output classification, loss function used is crossentropy\n",
        "\n",
        "several metrics can be entered as a list, but here we use accuracy only"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0APRCyQ_pvP"
      },
      "source": [
        "ann.compile(optimizer = 'adam',  loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z38lbOm0D0Ko"
      },
      "source": [
        "### Training the ANN \n",
        "the method to train any ML model is fit method\n",
        "\n",
        "Batch learning is more efficient because of comparing prediction results one-by-one to compute and reduce the loss, we compute several results in a batch.\n",
        "\n",
        "batch_size paarmeter tells the number of predictions we want to have in the batch to be compared to. classic value chosen is 32, but it can be changed\n",
        "\n",
        "epochs - number of full cycles of training. Make sure to not choose a small number because a NN needs sufficient epochs to learn properly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5z3E7ygBlWf",
        "outputId": "7ab17467-1b88-47b5-aaff-f99271f4adb7"
      },
      "source": [
        "ann.fit(x_train, y_train, batch_size = 32, epochs = 100)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "63/63 [==============================] - 1s 1ms/step - loss: 0.6363 - accuracy: 0.7040\n",
            "Epoch 2/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.5834 - accuracy: 0.8000\n",
            "Epoch 3/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.5396 - accuracy: 0.7995\n",
            "Epoch 4/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.5067 - accuracy: 0.7995\n",
            "Epoch 5/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.4857 - accuracy: 0.7995\n",
            "Epoch 6/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.4723 - accuracy: 0.7995\n",
            "Epoch 7/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7995\n",
            "Epoch 8/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7995\n",
            "Epoch 9/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.4522 - accuracy: 0.7995\n",
            "Epoch 10/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.7990\n",
            "Epoch 11/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.4454 - accuracy: 0.7995\n",
            "Epoch 12/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.4433 - accuracy: 0.7990\n",
            "Epoch 13/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7995\n",
            "Epoch 14/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.4399 - accuracy: 0.8015\n",
            "Epoch 15/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.4381 - accuracy: 0.8020\n",
            "Epoch 16/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.4370 - accuracy: 0.8010\n",
            "Epoch 17/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.8020\n",
            "Epoch 18/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.4345 - accuracy: 0.8030\n",
            "Epoch 19/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.4333 - accuracy: 0.8040\n",
            "Epoch 20/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.4324 - accuracy: 0.8040\n",
            "Epoch 21/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.8055\n",
            "Epoch 22/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.4306 - accuracy: 0.8060\n",
            "Epoch 23/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.8090\n",
            "Epoch 24/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.4287 - accuracy: 0.8075\n",
            "Epoch 25/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.4281 - accuracy: 0.8105\n",
            "Epoch 26/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.4267 - accuracy: 0.8095\n",
            "Epoch 27/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.4260 - accuracy: 0.8085\n",
            "Epoch 28/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.4250 - accuracy: 0.8095\n",
            "Epoch 29/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.4238 - accuracy: 0.8105\n",
            "Epoch 30/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.4231 - accuracy: 0.8080\n",
            "Epoch 31/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.8085\n",
            "Epoch 32/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.4205 - accuracy: 0.8105\n",
            "Epoch 33/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.8100\n",
            "Epoch 34/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.4182 - accuracy: 0.8115\n",
            "Epoch 35/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.4170 - accuracy: 0.8145\n",
            "Epoch 36/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.4161 - accuracy: 0.8155\n",
            "Epoch 37/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8195\n",
            "Epoch 38/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.8195\n",
            "Epoch 39/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.8220\n",
            "Epoch 40/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.4111 - accuracy: 0.8260\n",
            "Epoch 41/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.4094 - accuracy: 0.8235\n",
            "Epoch 42/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.4078 - accuracy: 0.8255\n",
            "Epoch 43/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.4064 - accuracy: 0.8265\n",
            "Epoch 44/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.4053 - accuracy: 0.8280\n",
            "Epoch 45/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.4039 - accuracy: 0.8260\n",
            "Epoch 46/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.4024 - accuracy: 0.8270\n",
            "Epoch 47/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.4006 - accuracy: 0.8275\n",
            "Epoch 48/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.3989 - accuracy: 0.8290\n",
            "Epoch 49/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.3971 - accuracy: 0.8320\n",
            "Epoch 50/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.3956 - accuracy: 0.8320\n",
            "Epoch 51/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.3935 - accuracy: 0.8355\n",
            "Epoch 52/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.3922 - accuracy: 0.8340\n",
            "Epoch 53/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.3906 - accuracy: 0.8345\n",
            "Epoch 54/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.3894 - accuracy: 0.8355\n",
            "Epoch 55/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.3879 - accuracy: 0.8375\n",
            "Epoch 56/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.3862 - accuracy: 0.8385\n",
            "Epoch 57/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.3847 - accuracy: 0.8385\n",
            "Epoch 58/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.3835 - accuracy: 0.8395\n",
            "Epoch 59/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.3816 - accuracy: 0.8390\n",
            "Epoch 60/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.3803 - accuracy: 0.8390\n",
            "Epoch 61/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.3789 - accuracy: 0.8405\n",
            "Epoch 62/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.3778 - accuracy: 0.8405\n",
            "Epoch 63/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.3761 - accuracy: 0.8420\n",
            "Epoch 64/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8420\n",
            "Epoch 65/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.3741 - accuracy: 0.8425\n",
            "Epoch 66/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.3729 - accuracy: 0.8440\n",
            "Epoch 67/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.3726 - accuracy: 0.8450\n",
            "Epoch 68/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.3712 - accuracy: 0.8460\n",
            "Epoch 69/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.3704 - accuracy: 0.8465\n",
            "Epoch 70/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.8470\n",
            "Epoch 71/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.3689 - accuracy: 0.8470\n",
            "Epoch 72/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.3682 - accuracy: 0.8470\n",
            "Epoch 73/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.3674 - accuracy: 0.8460\n",
            "Epoch 74/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.3667 - accuracy: 0.8480\n",
            "Epoch 75/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.3661 - accuracy: 0.8485\n",
            "Epoch 76/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.3654 - accuracy: 0.8480\n",
            "Epoch 77/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.3651 - accuracy: 0.8480\n",
            "Epoch 78/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8500\n",
            "Epoch 79/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.3634 - accuracy: 0.8510\n",
            "Epoch 80/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.3630 - accuracy: 0.8520\n",
            "Epoch 81/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8520\n",
            "Epoch 82/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.3621 - accuracy: 0.8530\n",
            "Epoch 83/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.3616 - accuracy: 0.8530\n",
            "Epoch 84/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.3614 - accuracy: 0.8540\n",
            "Epoch 85/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.3610 - accuracy: 0.8520\n",
            "Epoch 86/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.3602 - accuracy: 0.8530\n",
            "Epoch 87/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.3603 - accuracy: 0.8530\n",
            "Epoch 88/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.3599 - accuracy: 0.8505\n",
            "Epoch 89/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.3594 - accuracy: 0.8545\n",
            "Epoch 90/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.3590 - accuracy: 0.8535\n",
            "Epoch 91/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.3586 - accuracy: 0.8535\n",
            "Epoch 92/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.3583 - accuracy: 0.8555\n",
            "Epoch 93/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.3583 - accuracy: 0.8550\n",
            "Epoch 94/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.3576 - accuracy: 0.8555\n",
            "Epoch 95/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.3573 - accuracy: 0.8540\n",
            "Epoch 96/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.3568 - accuracy: 0.8540\n",
            "Epoch 97/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.3567 - accuracy: 0.8525\n",
            "Epoch 98/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.3563 - accuracy: 0.8560\n",
            "Epoch 99/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.3557 - accuracy: 0.8570\n",
            "Epoch 100/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.3559 - accuracy: 0.8570\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff74cfa2c10>"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDBiiLKYGaHF"
      },
      "source": [
        "As we can observe, the accuracy is evolving over the epochs, and ultimately converging around 0.86. \n",
        "Which means that out of 100 observations we had 86 accurate predictions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNG68IpuHPjT"
      },
      "source": [
        "## Part 4: Making predictions and evaluating the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIlANp0QHkFH"
      },
      "source": [
        "### Predicting the result of a single observation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6GYMldXIghs"
      },
      "source": [
        "We can now predict if a customer with following details would leave the bank or not:\n",
        "Geography: France, Credit Score: 600, Gender: Male, Age: 40, Tenure: 3 years, Balance: $ 60,000 \n",
        "\n",
        "Number of products: 2, does this customer have a credit card? Yes, Is this customer an Active Member? Yes, Estimated Salary: $ 50,000\n",
        "\n",
        "An input to the predict method must be a 2-d array, hence the double pair of square brackets.\n",
        "\n",
        "For the geography variable, we must enter the value of dummy variable [1 0 0]. Rest as they are or binary wherever necessary\n",
        "\n",
        "**NOTE: Predict method should be called on with the same scaling was applied in the training. so we use sc.transform**\n",
        "\n",
        "REMEMBER: When compiling an ANN to an optimiser, a loss function and metrics, in the output we chose a sigmoid function which will now render the prediction in the form of a probability"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20q8tCUbBnTi",
        "outputId": "0e343879-e945-4c47-bf80-61fc3af5817c"
      },
      "source": [
        "print(ann.predict(sc.transform([[1, 0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000 ] ])))"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.09622014]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lu6P91HwNGJc"
      },
      "source": [
        "So, the probability of this customer leaving the bank is very less (0.1)\n",
        "\n",
        "If instead of a probability, we want a  binary outcome whether a customer will leave the bank or not, we can instruct the predict method to tell us whether the probability is greater than 0.5 or not. see below\n",
        "\n",
        "different values for threshold could be chosen instead of 0.5, depending on critical values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNn2faRJMzLP",
        "outputId": "94302267-f08a-418f-82e1-5fe86e661e29"
      },
      "source": [
        "print(ann.predict(sc.transform([[1, 0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000 ] ])) > 0.5)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[False]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUhwIQCWOejQ"
      },
      "source": [
        "So the customer would not leave the bank then"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQcrRJXNOjL-"
      },
      "source": [
        "### Predicting the Test set results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1Fs6__bPTFx",
        "outputId": "1ff033f1-dea0-4082-995c-371d7452a4fb"
      },
      "source": [
        "y_pred = ann.predict(x_test)\n",
        "y_pred = (y_pred > 0.5) # This is done to get a binary outcome because y_pred is a probability. 0.5 is the threshold here\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred), 1), y_test.reshape(len(y_test), 1)), 1))"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0]\n",
            " [0 1]\n",
            " [0 0]\n",
            " ...\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8JTgaszQzgq"
      },
      "source": [
        "On the left we have vector predictions y_pred, and on the right is vector real results y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzCrTflWPLng"
      },
      "source": [
        "### The Confusion Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBxauYA5PPqE"
      },
      "source": [
        "To compute the final accuracy of the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bbk2nJHpNzP1",
        "outputId": "551bbfc2-a467-49b8-c1ab-cf7d0e214be7"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[6083  281]\n",
            " [ 989  647]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.84125"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWJMZMgFRycm"
      },
      "source": [
        "So out of 100 customers, 85 were predicted correctly whether they'd stay or leave the bank"
      ]
    }
  ]
}
